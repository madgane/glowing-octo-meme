\review{The authors have addressed many of my previous comments. However, there are still several major issues that need further clarification.}

\vspace{1eM}
\underline{\textit{Reply:}} We thank the reviewer for providing useful comments. The comments are constructive and helped us to improve the manuscript better.

\begin{enumerate}

\cmnt{1} \review{The revised paper did not address my previous comment about how to select the sub-channel ordering. I understand that finding the best sub-channel ordering requires exhaustive search which has extremely high complexity. But it is important to provide a guidance on what would be a good choice of sub-channel ordering. For example, can we achieve a good performance by using a low complexity ordering algorithm such as a greedy sub-channel ordering algorithm?}

\resp We apologize for not discussing the sub-channel ordering in a detailed manner. We have included the guidelines for selecting the sub-channel ordering based on channel gains, \textit{i.e}, greedy selection. In random ordering scheme, after finding the precoders for a current sub-channel, we can choose any previously unselected sub-channels as the next candidate sub-channel for which the precoders are identified using the updated backlogged packets. As suggested by the reviewer, the greedy sub-channel ordering is based on sorting the best channel from each sub-channel, which is obtained by finding the highest channel norm between the users from the respective serving \ac{BS}. Note that the users channel used in the ordering procedure is the channel seen by the users with the corresponding serving \acp{BS} only.

However, it may not be optimal for all system configurations, since the ordering scheme should also consider the number of backlogged packets associated with each user. We have 
emphasized this issue by comparing various ordering schemes for the same system model with two different set of backlogged packets associated with each user. Even though we are not including it in the paper, we have included in the response letter to answer the reviewer's question. We considered a system with \eqn{N = 4} sub-channels, \eqn{N_B = 2} \acp{BS} with \eqn{N_T = 4} transmit antennas and \eqn{K = 12} single antenna users. The \ac{PL} is distributed uniformly over \eqn{[0,-3]} dB. The number of backlogged packets assumed for each user is provided in the corresponding captions in Fig. \ref{fig-review-1}.
\begin{figure*}[h!]
	\centering
	\subfloat[][Number of backlogged packets for each user in bits \eqn{Q_k = [11,8,14,6,6,2,10,10,5,6,9,5]}]{
		\includegraphics[width=0.8\textwidth]{reviewer_2_Q1B.eps}
		\label{fig-review-1a}
	}
	\hfill
	\subfloat[][Number of backlogged packets for each user in bits \eqn{Q_k = [8,9,12,8,12,5,4,10,8,5,7,9]}]{
		\includegraphics[width=0.8\textwidth]{reviewer_2_Q1A.eps}
		\label{fig-review-1b}
	}
	\caption{Convergence of the algorithms for \me{\lbrace N,N_B,K,N_T,N_R \rbrace = \lbrace 4,2,12,4,1 \rbrace} using \me{\ell_1} norm}
	\label{fig-review-1}
\end{figure*}

Fig. \ref{fig-review-1} compares different ordering of sub-channels with the total number of backlogged packets remaining in the system as the metric. As can be seen from Fig. \ref{fig-review-1a}, the greedy sub-channel ordering provides a favorable way of choosing the sub-channels to minimize the total number of backlogged packets. However in Fig. \ref{fig-review-1b}, the greedy sub-channel ordering is not an efficient strategy in determining the order in which the sub-channels are to be chosen. We have included the discussions regarding the greedy sub-channel ordering in the revised manuscript as a heuristic method under Section III-D final paragraph. Note that as the number of users in the system increases, all channel ordering provides favorable order to minimize the total number of backlogged packets in the system.

\cmnt{2} \review{The authors mentioned that the signaling overhead of the distributed algorithm can be reduced by using a smaller number of iterations \eqn{J_{\max}}. But still, you didn't answer my question about whether the signaling overhead of the distributed algorithm is smaller than the centralized algorithm. You should first analyze the signaling overhead of the distributed algorithm for fixed \eqn{J_{\max}} and the signaling overhead of the centralized algorithm. Then you should point out under what \eqn{J_{\max}} the distributed algorithm will have less signaling overhead than the centralized algorithm. Is it possible that the distributed algorithm always has more signaling overhead than the centralized algorithm even when \eqn{J_{\max} = 1}? Finally, there is a trade-off between performance and signaling overhead (\eqn{J_{\max}}) for the distributed algorithm. For the same signaling overhead (we can control \eqn{J_{\max}} to make the signaling overhead of the distributed algorithm approximately equal to that of the centralized algorithm), does the distributed algorithm achieve better performance than the centralized algorithm?}

\resp
	We thank the reviewer for the insightful comment and we apologize for the lack of clarity in explaining this information in our earlier manuscript.
	\begin{enumerate}
		\item The amount of signaling overhead of the distributed algorithm and the centralized one depends on the system model of consideration. For example, let us consider a model with \eqn{N = 1} sub-channels ,\eqn{N_B = 2} \acp{BS}, and \eqn{K = 4} users in total, each \ac{BS} serving \eqn{2} users. Let \eqn{N_T = 4} be the number of transmit antennas and \eqn{N_R = 1} be the number of receive antenna at each user. In this scenario, the amount of information exchange to perform a centralized algorithm by a common controller requires the knowledge of complete channel matrices interlinked in the system, \textit{i.e}, the number of users times the \acp{BS}. 
		
		In order to quantify the total number of bits required to be exchanged, let us assume that each complex channel for a single-input single-output requires \eqn{10} bits, \textit{i.e}, \eqn{4} bits for amplitude and \eqn{6} bits for phase (assuming phase is important) or it can be a equal share of \eqn{5} bits for both amplitude and phase. Using this assumption, the total number of channel information in bits to be exchanged via backhaul requires \eqn{10 \times K \times N_B \times N_R \times N_T = 320} bits. On the other hand, for the distributed case, let us consider \eqn{6} bits are required to quantize the scalar interference in the consensus vectors. Consequently, the proposed distributed solutions require \eqn{6 \times 2 \times 2} bits to be exchanged in each iteration. 
		
		In this example, for the same amount of signaling overhead as in centralized method, we can performance only up to 6 SCA updates for \eqn{J_{\max} = 2} (\textit{i.e.}, two updates for ADMM part). This may not be sufficient for the distributed algorithms to attain the same performance as the centralized method. However, as the number of sub-channels, users and/or the antenna element increases, it may not be a feasible option to feedback the \ac{CSI} across the coordinating \acp{BS} to the centralized controller. In addition to comparing the signaling overhead, we also need to consider the effects of the quantization of the \ac{CSI} on the performance of a centralized algorithm, which is beyond the scope of our paper. Generally, the performance is significantly degraded if the \ac{CSI} is quantized \cite{nam_robust}. Moreover, in the centralized algorithm, resulting transmit precoders need to be exchanged with the corresponding \acp{BS} before the actual transmission, involving huge overhead in the backhaul.
		
		\item Using the above discussion, we can say that when the system size is huge, it would be favorable to consider the distributed algorithm over the centralized approach due to the huge signaling overhead involved in exchanging the channels.
		
		\item In particular, \ac{ADMM} and primal approach requires significant overhead compared to the centralized algorithm for a small system, since by exchanging the quantized channels, each \ac{BS} can perform the centralized algorithm independently until convergence. However, it depends on the channel quantizer, which is likely to be based on the channel density function (eg. Lloyd quantizer). For a system involving more coordinating \acp{BS}, users and antenna elements, it would be beneficial to use distributed algorithm with \eqn{J_{\max} > 1} to have a strictly monotonic decrease in the objective. If we set \eqn{J_{\max} = 1}, the proposed algorithms still converge (but monotonicity of SCA is not guaranteed). It can be easily verified from Fig. \ref{fig-review-2-a}, which has same configuration as that of Fig. \ref{fig-review-1a}.
		\begin{figure}[h!]
			\centering
			\includegraphics[width=0.8\columnwidth]{reviewer_2_Q1C.eps}
			\caption{Convergence of the algorithms for \me{\lbrace N,N_B,K,N_T,N_R \rbrace = \lbrace 4,2,12,4,1 \rbrace} using \me{\ell_1} norm}
			\label{fig-review-2-a}
		\end{figure}
		Note that Fig. \ref{fig-review-2-a} plots the queue deviation at the \ac{SCA} update points only. The number of backlogged packets in each \ac{ADMM} iteration is not shown for clarity reason.		
		
	\end{enumerate}
	
	We have included the above discussions in the first and last paragraphs of Section IV-C, and the paragraph before Section VI (i.e., the conclusion section). In reality, since the channel is time-correlated, it is enough to update the precoders once per radio frame. Thus, it is not necessary for the distributed algorithm to converge until the end. Instead, the decentralized parts only need to follow the fading process when \eqn{J_{\max} > 1}. 
	
	The performance of the distributed algorithm based on dual decomposition scheme was discussed for the time-correlated fading in Section C of [13], which shows that it is enough for the distributed precoder design to follow the fading process to provide desired performance. The distributed algorithm for the time correlated case is beyond the scope of our paper and thus is not considered in the current manuscript. However, we take this opportunity to show a plot demonstrating this behavior for the \ac{KKT} based algorithm presented in Section IV-C of the manuscript.
	\begin{figure}[h!]
		\centering
		\includegraphics[width=0.8\columnwidth]{reviewer_2_Q2.eps}
		\caption{Average number backlogged packets after each transmission for system \me{\lbrace N,N_B,K,N_T,N_R \rbrace = \lbrace 4,2,16,4,2 \rbrace} evaluated for \eqn{500} slots}
		\label{fig-review-2}
	\end{figure}
		
	Fig. \ref{fig-review-2} compares the performance of the distributed \ac{KKT} approach presented in Section IV-C for different iteration. The signaling requirements are outlined in Algorithm 3 and the overhead involved in the signaling is penalized in the achievable rate of the users. We considered that the channel is coherent over \eqn{N_S = 100} symbols and the precoder update is performed by exchanging the equivalent channel for \eqn{J_{\max} = 3,5,10} number of iterations. The overhead is considered as \eqn{\tilde{t}_{l,k,n} = (1 - \frac{J_{\max}}{N_S}) \times t_{l,k,n}}, where \eqn{\tilde{t}_{l,k,n}} is the rate seen by the user and the factor \eqn{(1 - \frac{J_{\max}}{N_S})} is considered as a penalty involved due to the precoder exchange. The average number of backlogged packets after each transmission slot is evaluated as 
	\begin{equation}
	\chi = \sum_{k = 1}^K \; [ Q_k - \tilde{t}_k ]^+
	\end{equation}
	
	Unlike the distributed algorithm, the centralized scheme presented in Fig. \ref{fig-review-2} has no penalty term and it is used as a benchmark for the other figures. In order to improve the performance of the distributed scheme, the operating point involved in the \ac{SCA} algorithm is considered from the earlier frame instead of starting initializing randomly. Since we use \ac{KKT} approach, we can either use all users in the system for the precoder design or we can utilize single-cell MU-MIMO user selection presented in the literature to limit the number of users for which the precoders are designed, which leads to the faster convergence. As we can see from Fig. \ref{fig-review-2}, as the arrival rate per user increases, the performance of \ac{KKT} schemes with \eqn{J_{\max} = 3,5,10} converges since the number of backlogged packets are significantly large, therefore, the same set of users will be served by the algorithm with better precoders by utilizing the memory. 
	
	In spite of using memory and prior scheduling in the \ac{KKT} approach, isolated single \ac{BS} processing performs much better than the distributed scheme due to the limited number of iterations allowed in the algorithm. Note that the precoders are not updated for the desired users until convergence, after the limited number of iterations. However, if we perform the single cell precoder design by considering the neighboring precoders as fixed after the recent exchange as discussed in [28], we can improve the performance significantly for Algorithm 3 as shown by red curves in Fig. \ref{fig-review-2}. In this approach, in between each exchange across the coordinating \acp{BS}, each \ac{BS} will perform \eqn{J_{\max} = 20} with the neighboring precoders as fixed. Once the iterations are performed to update the precoders, it is then exchanged across the coordinating \acp{BS} to perform the same procedure as mentioned earlier. 

\cmnt{3} \review{If the authors can't prove the convergence of the ADMM algorithm (or the decomposition approach via KKT conditions) in Section IV.B, then at least, you should discuss the property of the fixed point of the algorithm. For example, does there exist a fixed point of the algorithm? If so, is the fixed point of the algorithm unique? Is any fixed point of the algorithm also the optimal solution of the original problem in (20)? Assuming that the ADMM algorithm converges to a fixed point, will the interference vector in (39) converges to the actual interference in the network? These questions must be clarified in the paper. Otherwise, it is not clear how the ADMM algorithm is related to the original problem in (20). Similar questions should also be answered for the decomposition approach via KKT conditions. }

\resp We thank the reviewer for raising the important concern regarding the convergence issue of the distributed algorithm with limited number of iterations. In view of this, we have updated the manuscript to include the discussion on the convergence of the distributed algorithms with a limited number of iterations in the third paragraph of Appendix B after (57). Since the distributed algorithm cannot be guaranteed to be monotonic in each iteration, it is not possible to prove the convergence of the algorithm. However, if the algorithm is allowed to converge or iterated to guarantee the monotonicity of the objective, it is possible to prove the convergence based on the discussions provided in the manuscript. 
\begin{itemize}
\item If there exists a fixed point or a set of fixed points for the original nonconvex problem in (16), then the proposed centralized algorithm in Section III-B and III-C finds at least one such point if iterated until convergence, which is provided in Appendix A. In order to find a unique fixed point, we regularize the objective function in (16) with a quadratic penalty term as discussed in Appendix A to transform the objective as a strongly convex function.
\item If the distributed algorithm is carried out for a limited number of iterations, it is not guaranteed to achieve a fixed point even if the outer \ac{SCA} update is performed for a large number of iterations. By this approach, the distributed approaches are not guaranteed to converge to a stationary point. In all our simulations on the primal and the \ac{ADMM} approach, we have set \eqn{J_{\max} = 20} in order to guarantee the monotonicity of the objective.
\item Unless the objective function is regularized with a strongly convex term as in Appendix A-C, the uniqueness of the iterates is not guaranteed. 
\item In each \ac{SCA} update, if the distributed algorithms are allowed to converge to the centralized solution, then the overall convergence will be a stationary point of the original nonconvex problem by following the same argument as that of the centralized algorithm.
\item Since the coupling between the distributed precoder designs is the interference between the BSs and the users, in the \ac{ADMM} approach, the interference is treated as a local variable, which is then included in the precoder design problem for each coordinating BS. This is treated as a local variable for individual \acp{BS}. Note that the local variable is an assumption made by the BS on the actual interference caused by the neighboring BSs. Since the actual interference caused is different, the consensus has to be made between the local interference variable maintained at each BS with the global consensus interference variable, which is nothing but the average between the corresponding BSs interference. These discussions have been made in the revised manuscript in Section IV-B. For reference purpose, we have also referred the interested reader to [11], which discusses exclusively about the ADMM approach. Upon convergence of the \ac{ADMM} approach, the interference vector is equal to the actual interference seen in the network.
\end{itemize}

\end{enumerate}

\bibliographystyle{./../../Styles/IEEEtran}
\bibliography{./../../Library/IEEEabrv,./../../Library/kirja_survey}
