
In this section, we discuss an alternative way to decentralize the precoder design across the coordinating \acp{BS} in \me{\mc{B}} based on the \ac{MSE} reformulation method discussed in Section \ref{sec-3.3}. In contrast to Section \ref{sec-4.1} and \ref{sec-4.2}, the problem is solved using the \ac{KKT} conditions in which the transmit precoders, receive beamformers and the subgradient updates are performed at the same instant to minimize the global queue deviation objective with few number of iterations. The proposed methods in this section provide algorithms that can be of practical importance owing to the limited signaling requirements. \review{We consider an idealized \ac{TDD} system due to the knowledge of complete channel information at the transmitter}.  Similar work has been considered for the \ac{WSRM} problem with minimum rate constraints in \cite{kaleva2013decentralized,kaleva2013primal}. Since the formulation in \cite{kaleva2013decentralized,kaleva2013primal} are similar to the \ac{Q-WSRME} scheme with an additional maximum rate constraint \eqref{eqn-3.1.4}, it requires explicit dual variables to handle the maximum rate constraint, thereby making the problem difficult to solve in an iterative manner.

In the proposed \ac{JSFRA} formulation, the maximum rate constraints are implicitly handled by the objective function without the need of explicit constraints. However, the \ac{KKT} conditions cannot be formulated due to the non-differential objective function. The non-differentiability is due to the absolute value operator present in the norm function. In order to make the objective function differentiable, we consider the following two cases for which the absolute operator can be ignored without affecting the optimal solution, namely,
\begin{itemize}
\item when the exponent \me{q} is even, or
\item when the number of backlogged packets of each user is large enough, \textit{i.e}, \me{Q_k \gg \sum_{n=1}^N \sum_{l=1}^L {t}_{l,k,n}} to ignore the absolute operator, which means also ignoring the queues in the first place as well.
\end{itemize}

With the assumption of either one of the above conditions to be true, the problem in \eqref{eqn-mse-2} can be written as
\iftoggle{single_column}{\allowdisplaybreaks
\begin{IEEEeqnarray}{rCl}\label{kkt-mse-1}
\underset{\substack{t_{l,k,n},\mvec{m}{l,k,n}, \\ \epsilon_{l,k,n}, \mvec{w}{l,k,n}}}{\text{minimize}} &\hspace{0.5cm}& \sum_{b \in \mc{B}} \sum_{k \in \mc{U}_b} \, a_k \, \Big ( Q_k - \sum_{n = 1}^N \sum_{l = 1}^{L} t_{l,k,n} \Big )^q \IEEEyessubnumber \label{kkt-mse-1.1} \\
\text{subject to} & \hspace{0.5cm} & \nonumber \\
\alpha_{l,k,n} : & \hspace{0.5cm} & \left | 1 - \mvec{w}{l,k,n}^\herm \mvec{H}{b_k,k,n} \mvec{m}{l,k,n} \right |^2 +  \enoise + \sum_{\mathclap{(x,y) \neq (l,k)}} \left | \mvec{w}{l,k,n}^\herm \mvec{H}{b_y,k,n} \mvec{m}{x,y,n} \right |^2 \leq \epsilon_{l,k,n} \eqspace \IEEEyessubnumber \label{kkt-mse-1.2} \\
\sigma_{l,k,n} : & \hspace{0.5cm} & \log(\tilde{\epsilon}_{l,k,n}) + \frac{\left ( {\epsilon}_{l,k,n} - \tilde{\epsilon}_{l,k,n} \right ) }{\tilde{\epsilon}_{l,k,n}} \leq -t_{l,k,n} \, \log(2) \IEEEyessubnumber \label{kkt-mse-1.3} \\
%\delta_b : & \hspace{0.5cm} & \sum_{n = 1}^N \sum_{k \in \mathcal{U}_b} \sum_{l = 1}^L \trace \, (\mvec{m}{l,k,n} \mvec{m}{l,k,n}^\herm) \leq P_{{\max}}, \fall b, \IEEEyessubnumber \label{kkt-mse-1.4}
\end{IEEEeqnarray}
}{
\begin{IEEEeqnarray}{Rl}\label{kkt-mse-1}
	\underset{\substack{t_{l,k,n},\mvec{m}{l,k,n}, \\ \epsilon_{l,k,n}, \mvec{w}{l,k,n}}}{\text{minimize}} & \quad \sum_{b \in \mc{B}} \sum_{k \in \mc{U}_b} \, a_k \, \Big ( Q_k - \sum_{n = 1}^N \sum_{l = 1}^{L} t_{l,k,n} \Big )^q \IEEEyessubnumber \label{kkt-mse-1.1} \\
	\text{subject to} & \nonumber \\
	\alpha_{l,k,n} : &  \left | 1 - \mvec{w}{l,k,n}^\herm \mvec{H}{b_k,k,n} \mvec{m}{l,k,n} \right |^2 +  \enoise \nonumber \\
	& + \sum_{\mathclap{(x,y) \neq (l,k)}} \left | \mvec{w}{l,k,n}^\herm \mvec{H}{b_y,k,n} \mvec{m}{x,y,n} \right |^2 \leq \epsilon_{l,k,n} \IEEEyessubnumber \label{kkt-mse-1.2} \\
	\sigma_{l,k,n} : &  \log_2(\tilde{\epsilon}_{l,k,n}) + \frac{\left ( {\epsilon}_{l,k,n} - \tilde{\epsilon}_{l,k,n} \right ) }{\log(2)\tilde{\epsilon}_{l,k,n}} \leq -t_{l,k,n} \IEEEyessubnumber \label{kkt-mse-1.3} \\
	\delta_b : & \sum_{n = 1}^N \sum_{k \in \mathcal{U}_b} \sum_{l = 1}^L \trace \, (\mvec{m}{l,k,n} \mvec{m}{l,k,n}^\herm) \leq P_{{\max}}, \fall b, \IEEEyessubnumber \eqspace \label{kkt-mse-1.4}
\end{IEEEeqnarray}
}
where \me{\alpha_{l,k,n},\sigma_{l,k,n}} and \me{\delta_b} are the dual variables corresponding to the constraints defined in \eqref{kkt-mse-1.2}, \eqref{kkt-mse-1.3} and \eqref{kkt-mse-1.4}. 

The problem in \eqref{kkt-mse-1} is solved using the \ac{KKT} expressions, which are obtained by the derivative of the Lagrangian function w.r.t the primal and the dual variables, complementary slackness conditions, and the primal, dual feasibility requirements as shown in Appendix \ref{a-1}. Upon solving, we obtain the iterative solution as
\iftoggle{single_column}{
\begin{IEEEeqnarray}{rCl} \label{kkt-mse-4}
\mvec{m}{l,k,n}^{(i)} &=& \Big ( \sum_{x \in \mc{U}} \sum_{y=1}^L \alpha_{y,x,n}^{(i-1)} \mvec{H}{b_k,x,n}^\herm \mvec{w}{y,x,n}^{(i-1)} \mvec{w}{y,x,n}^{\herm \, {(i-1)}} \mvec{H}{b_k,x,n} + \delta_b \mbf{I}_{N_T} \Big )^{-1} \alpha^{(i-1)}_{l,k,n} \mvec{H}{b_k,k,n}^\herm \mvec{w}{l,k,n}^{(i-1)} \IEEEyessubnumber \label{kkt-mse-4.3} \\
\mvec{w}{l,k,n}^{(i)} &=& \Big ( \sum_{x\in\mc{U}}\sum_{y=1}^L \mvec{H}{b_x,k,n} \mvec{m}{y,x,n}^{(i)} \mvec{m}{y,x,n}^{\herm \, (i)} \mvec{H}{b_{x},k,n}^\herm + \mathbf{I}_{N_R} \Big ) ^{-1} \; \mvec{H}{b_k,k,n} \; \mvec{m}{l,k,n}^{(i)}. \IEEEyessubnumber \label{kkt-mse-4.6}\\
\epsilon_{l,k,n}^{(i)} &=& \left | 1 - \mvec{w}{l,k,n}^{\herm \, (i)} \mvec{H}{b_k,k,n} \mvec{m}{l,k,n}^{(i)} \right |^2 + \sum_{\mathclap{(x,y) \neq (l,k)}} \left | \mvec{w}{l,k,n}^{\mathrm{H} \, (i)} \mvec{H}{b_y,k,n} \mvec{m}{x,y,n}^{(i)} \right |^2 + N_0 \, \|\mvec{w}{l,k,n}^{(i)}\|^2 \IEEEyessubnumber \label{kkt-mse-4.4} \\
t_{l,k,n}^{(i)} &=&  -\log_2(\epsilon_{l,k,n}^{(i-1)}) - \frac{\left ( \epsilon_{l,k,n}^{(i)} - \epsilon_{l,k,n}^{(i-1)} \right ) }{\log(2) \, \epsilon_{l,k,n}^{(i-1)}} \IEEEyessubnumber \label{kkt-mse-4.5} \\
\sigma_{l,k,n}^{(i)} &=& \left [\tfrac{a_k \, q}{\log(2)}  \, \Big (Q_k - \sum_{n = 1}^N \sum_{l=1}^L t_{l,k,n}^{(i)} \Big )^{(q-1)}\right ]^+  \IEEEyessubnumber \label{kkt-mse-4.2} \\
\alpha^{(i)}_{l,k,n} &=& \alpha^{(i-1)}_{l,k,n} + \rho \left ( \tfrac{\sigma_{l,k,n}^{(i)}}{\epsilon_{l,k,n}^{(i)}} - \alpha^{(i-1)}_{l,k,n} \right ) \IEEEyessubnumber \label{kkt-mse-4.1}
\end{IEEEeqnarray}
}{{\allowdisplaybreaks
\begin{IEEEeqnarray}{ll} \label{kkt-mse-4}
	\mvec{m}{l,k,n}^{(i)} =& \Big ( \sum_{x \in \mc{U}} \sum_{y=1}^L \alpha_{y,x,n}^{(i-1)} \mvec{H}{b_k,x,n}^\herm \mvec{w}{y,x,n}^{(i-1)} \mvec{w}{y,x,n}^{\herm \, {(i-1)}} \mvec{H}{b_k,x,n} \nonumber \\
	& \qquad {} + \delta_b \mbf{I}_{N_T} \Big )^{-1} \alpha^{(i-1)}_{l,k,n} \mvec{H}{b_k,k,n}^\herm \mvec{w}{l,k,n}^{(i-1)} \IEEEyessubnumber \label{kkt-mse-4.3} \\
	\mvec{w}{l,k,n}^{(i)} =& \Big ( \sum_{x\in\mc{U}}\sum_{y=1}^L \mvec{H}{b_x,k,n} \mvec{m}{y,x,n}^{(i)} \mvec{m}{y,x,n}^{\herm \, (i)} \mvec{H}{b_{x},k,n}^\herm \nonumber \\
	& \qquad {} + \mathbf{I}_{N_R} \Big ) ^{-1} \; \mvec{H}{b_k,k,n} \; \mvec{m}{l,k,n}^{(i)}. \IEEEyessubnumber \label{kkt-mse-4.6} \\
	\epsilon_{l,k,n}^{(i)} =& \left | 1 - \mvec{w}{l,k,n}^{\herm \, (i)} \mvec{H}{b_k,k,n} \mvec{m}{l,k,n}^{(i)} \right |^2 + N_0 \, \|\mvec{w}{l,k,n}^{(i)}\|^2 \nonumber \\
	& \qquad{} + \sum_{\mathclap{(x,y) \neq (l,k)}} \left | \mvec{w}{l,k,n}^{\mathrm{H} \, (i)} \mvec{H}{b_y,k,n} \mvec{m}{x,y,n}^{(i)} \right |^2 \IEEEyessubnumber \label{kkt-mse-4.4} \\
	t_{l,k,n}^{(i)} =&  -\log_2(\epsilon_{l,k,n}^{(i-1)}) - \tfrac{\left ( \epsilon_{l,k,n}^{(i)} - \epsilon_{l,k,n}^{(i-1)} \right ) }{\log(2) \, \epsilon_{l,k,n}^{(i-1)}} \IEEEyessubnumber \label{kkt-mse-4.5} \\
	\sigma_{l,k,n}^{(i)} =& \Big [\tfrac{a_k \, q}{\log(2)}  \, \Big (Q_k - \sum_{n = 1}^N \sum_{l=1}^L t_{l,k,n}^{(i)} \Big )^{(q-1)}\Big ]^+  \IEEEyessubnumber \label{kkt-mse-4.2} \\
	\alpha^{(i)}_{l,k,n} =& \alpha^{(i-1)}_{l,k,n} + \rho \left ( \tfrac{\sigma_{l,k,n}^{(i)}}{\epsilon_{l,k,n}^{(i)}} - \alpha^{(i-1)}_{l,k,n} \right ) \IEEEyessubnumber \label{kkt-mse-4.1}
\end{IEEEeqnarray}}}
Since the dual variables \me{\alpha^{(i)}} and \me{\sigma^{(i)}} are interdependent in \eqref{kkt-mse-4}, one has to be fixed to optimize for the other. So, \me{\alpha^{(i)}} is fixed to evaluate \me{\sigma^{(i)}} using \eqref{kkt-mse-4}. \review{At each iteration, the dual variables \me{\alpha^{(i)}} are linearly interpolated with any point between the fixed iterate \me{\alpha^{(i-1)}} and \me{\tfrac{\sigma^{(i)}}{\epsilon^{(i)}}} using a step size \me{\rho \in (0,1)}. The choice of \me{\rho} depends on the system model and it affects the convergence behavior of the algorithm. It is used to reduce the oscillations in the objective function when \me{\sigma^{(i)}} is negative due to over allocation.}
	
When the allocated rate \me{t_k^{(i-1)}} is greater than the number of queued packets \me{Q_k} for a user \me{k}, the corresponding dual variable \me{\sigma^{(i)}} will be negative and due to the projection operator \me{[x]^+} in \eqref{kkt-mse-4.2}, it will be zero, thereby forcing \me{\alpha_k^{(i)} < \alpha_k^{(i-1)}} as in \eqref{kkt-mse-4.1}. Once the \me{\alpha_k^{(i)}} is reduced, the precoder weight in \eqref{kkt-mse-4.3} is lowered to make the rate \me{t_k^{(i)} < t_k^{(i-1)}} eventually. \review{The choice of \me{\rho} is susceptible to the system model under consideration, which affects the convergence speed of the iterative algorithm. In our simulations, we fixed \me{\rho = 0.1} irrespective of the model under consideration.}

The \ac{KKT} expressions in \eqref{kkt-mse-4} are solved in an iterative manner by initializing the transmit and the receive beamformers \me{\mvec{m}{l,k,n},\mvec{w}{l,k,n}} with the single user beamforming and the \ac{MMSE} vectors. The dual variable \me{\alpha}'s are initialized with ones to have equal priorities to all the users in the system. Then the transmit and the receive beamformers are evaluated using the expressions in \eqref{kkt-mse-4}. The transmit precoder in \eqref{kkt-mse-4.3} depends on the \ac{BS} specific dual variable \me{\delta_b}, which can be found by bisection search satisfying the total power constraint \eqref{kkt-mse-1.4}. Note that the fixed \ac{SCA} operating point is given by \me{\tilde{\epsilon}_{l,k,n} = \epsilon_{l,k,n}^{(i-1)}}, which is considered in the expression \eqref{kkt-mse-4}.

\review{To devise an algorithm for a practical implementation, we assume the cross channels \me{\mvec{H}{b,k,n}, \forall k \in \bar{\mc{U}}_b} and the receive beamformers \me{\mvec{w}{l,k,n}} of all users in the system are known through uplink signaling}. We extend the decentralization methods discussed in \cite{komulainen2013effective}, for the current problem as follows. After receiving the updated transmit precoders from all \acp{BS} in \me{\mathcal{B}}, each user evaluates the \ac{MMSE} receiver in \eqref{kkt-mse-4.6} and notify them to the \acp{BS} via uplink precoded pilots. On receiving pilot signals, \acp{BS} update the \ac{MSE} in \eqref{mse-error} as 
\begin{equation}
\epsilon_{l,k,n}^{(i)} = 1 - \mvec{w}{l,k,n}^{(i)\herm} \mvec{H}{b_k,k,n} \mvec{m}{l,k,n}^{(i)}.
\end{equation}
Using the current \ac{MSE} value, \me{t_{l,k,n}^{(i)},\sigma_{l,k,n}^{(i)}}, and \me{\alpha_{l,k,n}^{(i)}} are evaluated using \eqref{kkt-mse-4.5}, \eqref{kkt-mse-4.2} and \eqref{kkt-mse-4.1}, and the updated dual variables \me{\alpha_{l,k,n}} are exchanged between the \acp{BS} to evaluate the transmit precoders \me{\mvec{m}{l,k,n}^{(i+1)}} for the next iteration. The \ac{SCA} operating point is also updated with the current \ac{MSE} value.

To avoid the back-haul exchanges between \acp{BS}, as an alternative approach, users may perform all processing required and \acp{BS} will update the precoders based on the feedback information from the users. Upon receiving the transmit precoders from \acp{BS}, each user will update the receive beamformer \me{\mvec{w}{l,k,n}}, the \ac{MSE} \me{\epsilon_{l,k,n}}, and the dual variables \me{\lambda_{l,k,n}} and \me{\alpha_{l,k,n}}. The updated \me{\alpha_{l,k,n}} and \me{\mvec{w}{l,k,n}} are notified to the \acp{BS} using two separate precoded uplink pilot symbols with \me{\tilde{\mbf{w}}_{l,k,n}^{(i)} = \sqrt{\alpha_{l,k,n}^{(i)}}\mvec{w}{l,k,n}^{\ast(i)}} and \me{\bar{\mbf{w}}_{l,k,n}^{(i)} = \alpha_{l,k,n}^{(i)}\mvec{w}{l,k,n}^{\ast(i)}} as the precoders. On receiving the precoded uplink pilots, each \ac{BS} use the effective channel \me{\mvec{H}{b,k,n}^{\mathrm{T}} \tilde{\mbf{w}}_{l,k,n}^{(i)}} and \me{\mvec{H}{b,k,n}^{\mathrm{T}} \bar{\mbf{w}}_{l,k,n}^{(i)}} in \eqref{kkt-mse-4.3} to update the transmit precoders, where \me{\mbf{x}^{\ast}} is the complex conjugate of \me{\mbf{x}}. Finally, Algorithm \ref{algo-4} outlines the distributed precoder design using the \ac{KKT} based \ac{MSE} reformulated \ac{JSFRA} problem.
\begin{algorithm}
 \SetAlgoLined
 \DontPrintSemicolon
 \BlankLine
 \SetKwInput{KwInit}{Initialize}
 \KwIn{\me{a_k, \, Q_k, \, \mvec{H}{b,k,n},\; \fall b \in \mathcal{B}, \, \fall k \in \mathcal{U}, \fall n \in \mathcal{N}}}
 \KwOut{\me{\mvec{m}{l,k,n}} and \me{\mvec{w}{l,k,n} \fall l \in \set{1,2,\dotsc,L}}}
 \KwInit{\me{i=1}, \me{\mbf{w}^{(0)}_{l,k,n}, \tilde{\epsilon}_{l,k,n}} randomly, dual variables \me{{\alpha}_{l,k,n}^{(0)} = 1}, and \me{I_{\max}} for certain value}
 \ForEach{\ac{BS} \me{b \in \mc{B}}}{
 initialize \me{i = 0} \;
 \Repeat{until convergence or \me{i \geq I_{\max}}}{
	update \me{\mvec{m}{l,k,n}^{(i)}} using \eqref{kkt-mse-4.3}, and perform downlink transmission \;
	find \me{\mvec{w}{l,k,n}^{(i)}} using \eqref{kkt-mse-4.6} at each user \;
	evaluate \me{\epsilon_{l,k,n}^{(i)}}, \me{t_{l,k,n}^{(i)}}, \me{\sigma_{l,k,n}^{(i)}} and \me{\alpha_{l,k,n}^{(i)}} using \eqref{kkt-mse-4.4} and \eqref{kkt-mse-4.5}, \eqref{kkt-mse-4.2} and \eqref{kkt-mse-4.1} at each user with the updated \me{\mvec{w}{l,k,n}^{(i)}} \;
	using precoded uplink pilots, \me{\mvec{m}{l,k,n}^{(i)}} and \me{\alpha_{l,k,n}^{(i)}} are notified to all \acp{BS} in \me{\mathcal{B}} \;
	\me{i = i + 1} \;
 }
 }
 \caption{\ac{KKT} approach for the \ac{JSFRA} scheme}
 \label{algo-4}
\end{algorithm}

\review{The Algorithm \ref{algo-4} outlines a practical way of implementing the transmit precoders in a distributed manner using \ac{OTA} signaling of the transmit precoders and the receive beamformers for certain iterations before the actual transmission of data is performed with it. Unlike \ac{PD} or \ac{ADMM} approach, all variables are updated at once, \textit{i.e}, the \ac{SCA} point of \me{\epsilon^{(i-1)}}, \ac{AO} update of \me{\mvec{w}{l,k,n}} and the dual variable \me{\alpha} using subgradient update, it is not guaranteed to obtain the same point as that of the centralized problem. Since the problem solution in \eqref{kkt-mse-4} is equivalent to the centralized formulation in \eqref{eqn-mse-2} if the receive beamformers \me{\mvec{w}{l,k,n}} and the \ac{MSE} operating point \me{\epsilon_{l,k,n}^{(i-1)}} are fixed and optimized for the transmit precoders \me{\mvec{m}{l,k,n}} and the dual variable \me{\alpha_{l,k,n}}, the problem is guaranteed to converge to the centralized solution. Note that it requires four nested loops to obtain the centralized solution, namely, the receive beamformer loop, \ac{MSE} operating point loop, dual variable update loop and the bisection method for finding the transmit precoders. In order to avoid this, the proposed method performs the group update of all variables to obtain the transmit and the receive beamformers with the limited number of iterations. If the step size \me{\rho < 1}, the algorithm for \me{\ell_2} norm will converge by using the arguments on controlling overallocation and the nonincreasing objective function, since the earlier iterates are the operating point for the current iteration.}

%\subsubsection*{Convergence}
%The iterative method presented in Algorithm \ref{algo-4} converges to a stationary point at each iteration. Since the \ac{SCA} point \me{\tilde{\epsilon}_{l,k,n}} and the receive beamformers are updated together at each iteration, the convergence proof can be argued based on the monotonic increase in the objective function at each iteration. In order to illustrate the convergence, we adopt the following argument. The transmit precoders in \eqref{kkt-mse-4.3} improves the objective function after each update following the \ac{SCA} operating point \me{\tilde{\epsilon}_{l,k,n}} update \cite{marks1978technical}. Furthermore, the \ac{MMSE} receivers are globally optimal for the fixed transmit precoders \cite{christensen2008weighted,wmmse_shi}, the alternating beamformer updates improve the objective function monotonically in spite of having a subgradient like update in \eqref{kkt-mse-4.1}.
%presented in Algorithm \ref{algo-4} converges to a stationary point if the dual variables \me{\alpha_{l,k,n}} are allowed to converge or for fixed number of iterations \me{J_{\max}}. The convergence of the dual variable is guaranteed, since the problem is convex by fixing the receive beamformers \me{\mvec{w}{l,k,n}} and the operating \ac{MSE} point \me{\epsilon_{l,k,n}} \cite{boyd2011distributed}. Once the dual variables are converged or iterated for certain accuracy, the receivers are updated using the \ac{MMSE} objective. Since the \ac{MMSE} receiver is optimal for the fixed transmit precoders, the objective function will improve or stays the same after the receiver update leading to a monotonic convergence of the iterative algorithm provided in \eqref{kkt-mse-4}.
