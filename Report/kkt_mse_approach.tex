In this section, we discuss an alternative way to decentralize the precoder design across the coordinating \acp{BS} in \me{\mc{B}} based on the \ac{MSE} reformulation method discussed in Section \ref{sec-3.3}. In contrast to Sections \ref{sec-4.1} and \ref{sec-4.2}, the problem is solved using the \ac{KKT} conditions in which the transmit precoders, receive beamformers and the subgradient updates are performed at the same time to minimize the global queue deviation objective with few number of iterations. \review{The alterantive way is motivated by the fact that the distributed approaches presented in the preceeding sections may not be efficient for large systems in terms of signaling overhead involved in exchanging the coupling variables and the receivers.}

In this section, we provide an algorithm that can be of practical importance owing to lower signaling requirements. We consider an idealized \ac{TDD} system due to the knowledge of complete channel information at the transmitter. Similar work has been considered for the \ac{WSRM} problem with minimum rate constraints in \cite{kaleva2013decentralized,kaleva2013primal}. Since the work in \cite{kaleva2013decentralized,kaleva2013primal} are similar to that of the \ac{Q-WSRME} scheme with an additional maximum rate constraint \eqref{eqn-3.1.4}, the formulations require explicit dual variables to handle the maximum rate constraint, thereby making the problem difficult to solve in an iterative manner.

In the proposed scheme, the maximum rate constraints are implicitly handled by the objective function without any need for explicit constraints. However, due to the non-differentiability of the objective, the \ac{KKT} conditions are not computationally useful to find the optimization variables. In order to make the objective function differentiable, we consider the following two cases for which the absolute operator can be ignored without affecting the optimal solution, namely,
\begin{itemize}
\item when the exponent \me{q} is even, or
\item when the number of backlogged packets of each user is large enough, \textit{i.e}, \me{Q_k \gg \sum_{n=1}^N \sum_{l=1}^L {t}_{l,k,n}} to ignore the absolute operator and queues in the first place as well.
\end{itemize}

With the assumption of either one of the above conditions, the problem in \eqref{eqn-mse-2} can be written as
\allowdisplaybreaks\iftoggle{single_column}{
\begin{IEEEeqnarray}{rCl}\label{kkt-mse-1} \neqsub
\underset{\substack{t_{l,k,n},\mvec{m}{l,k,n}, \\ \epsilon_{l,k,n}, \mvec{w}{l,k,n}}}{\text{minimize}} &\hspace{0.5cm}& \sum_{b \in \mc{B}} \sum_{k \in \mc{U}_b} \, a_k \, \Big ( Q_k - \sum_{n = 1}^N \sum_{l = 1}^{L} t_{l,k,n} \Big )^q \IEEEyessubnumber \label{kkt-mse-1.1} \\
\text{subject to} & \hspace{0.5cm} & \nonumber \\
\alpha_{l,k,n} : & \hspace{0.5cm} & \left | 1 - \mvec{w}{l,k,n}^\herm \mvec{H}{b_k,k,n} \mvec{m}{l,k,n} \right |^2 +  \enoise + \sum_{\mathclap{(x,y) \neq (l,k)}} \left | \mvec{w}{l,k,n}^\herm \mvec{H}{b_y,k,n} \mvec{m}{x,y,n} \right |^2 \leq \epsilon_{l,k,n} \eqspace \IEEEyessubnumber \label{kkt-mse-1.2} \\
\sigma_{l,k,n} : & \hspace{0.5cm} & \log(\tilde{\epsilon}_{l,k,n}) + \frac{\left ( {\epsilon}_{l,k,n} - \tilde{\epsilon}_{l,k,n} \right ) }{\tilde{\epsilon}_{l,k,n}} \leq -t_{l,k,n} \, \log(2) \IEEEyessubnumber \label{kkt-mse-1.3} \\
\delta_b : & \hspace{0.5cm} & \sum_{n = 1}^N \sum_{k \in \mathcal{U}_b} \sum_{l = 1}^L \trace \, (\mvec{m}{l,k,n} \mvec{m}{l,k,n}^\herm) \leq P_{{\max}}\; \fall b, \IEEEyessubnumber \label{kkt-mse-1.4}
\end{IEEEeqnarray}
}{\begin{IEEEeqnarray}{Rl}\label{kkt-mse-1} \neqsub
	\underset{\substack{t_{l,k,n},\mvec{m}{l,k,n}, \\ \epsilon_{l,k,n}, \mvec{w}{l,k,n}}}{\text{minimize}} & \quad \sum_{b \in \mc{B}} \sum_{k \in \mc{U}_b} \, a_k \, \Big ( Q_k - \sum_{n = 1}^N \sum_{l = 1}^{L} t_{l,k,n} \Big )^q \IEEEyessubnumber \label{kkt-mse-1.1} \\
	\text{subject to} & \nonumber \\
	\alpha_{l,k,n} : &  \left | 1 - \mvec{w}{l,k,n}^\herm \mvec{H}{b_k,k,n} \mvec{m}{l,k,n} \right |^2 +  \enoise \nonumber \\
	& + \sum_{\mathclap{(x,y) \neq (l,k)}} \left | \mvec{w}{l,k,n}^\herm \mvec{H}{b_y,k,n} \mvec{m}{x,y,n} \right |^2 \leq \epsilon_{l,k,n} \IEEEyessubnumber \label{kkt-mse-1.2} \\
	\sigma_{l,k,n} : &  \log_2(\tilde{\epsilon}_{l,k,n}) + \frac{\left ( {\epsilon}_{l,k,n} - \tilde{\epsilon}_{l,k,n} \right ) }{\log(2)\tilde{\epsilon}_{l,k,n}} \leq -t_{l,k,n} \IEEEyessubnumber \label{kkt-mse-1.3} \\
	\delta_b : & \sum_{n = 1}^N \sum_{k \in \mathcal{U}_b} \sum_{l = 1}^L \trace \, (\mvec{m}{l,k,n} \mvec{m}{l,k,n}^\herm) \leq P_{{\max}} \; \fall b \IEEEyessubnumber \eqspace \label{kkt-mse-1.4}
\end{IEEEeqnarray}}
where \me{\alpha_{l,k,n},\sigma_{l,k,n}} and \me{\delta_b} are the dual variables corresponding to the constraints defined in \eqref{kkt-mse-1.2}, \eqref{kkt-mse-1.3} and \eqref{kkt-mse-1.4}. 

The problem in \eqref{kkt-mse-1} is solved using the \ac{KKT} conditions which include stationarity, complementary slackness, and primal and dual feasibility requirement as shown in Appendix \ref{a-1}. In particular, we propose an iterative algorithm to compute a solution to the system of equations \eqref{kkt-mse-2} in Appendix \ref{a-1} as
\iftoggle{single_column}{
\begin{IEEEeqnarray}{rCl} \label{kkt-mse-4} \neqsub
\mvec{m}{l,k,n}^{(i)} &=& \Big ( \sum_{x \in \mc{U}} \sum_{y=1}^L \alpha_{y,x,n}^{(i-1)} \mvec{H}{b_k,x,n}^\herm \mvec{w}{y,x,n}^{(i-1)} \mvec{w}{y,x,n}^{\herm \, {(i-1)}} \mvec{H}{b_k,x,n} + \delta_b \mbf{I}_{N_T} \Big )^{-1} \alpha^{(i-1)}_{l,k,n} \mvec{H}{b_k,k,n}^\herm \mvec{w}{l,k,n}^{(i-1)} \IEEEyessubnumber \label{kkt-mse-4.3} \\
\mvec{w}{l,k,n}^{(i)} &=& \Big ( \sum_{x\in\mc{U}}\sum_{y=1}^L \mvec{H}{b_x,k,n} \mvec{m}{y,x,n}^{(i)} \mvec{m}{y,x,n}^{\herm \, (i)} \mvec{H}{b_{x},k,n}^\herm + \mathbf{I}_{N_R} \Big ) ^{-1} \; \mvec{H}{b_k,k,n} \; \mvec{m}{l,k,n}^{(i)} \IEEEyessubnumber \label{kkt-mse-4.6}\\
\epsilon_{l,k,n}^{(i)} &=& \left | 1 - \mvec{w}{l,k,n}^{\herm \, (i)} \mvec{H}{b_k,k,n} \mvec{m}{l,k,n}^{(i)} \right |^2 + \sum_{\mathclap{(x,y) \neq (l,k)}} \left | \mvec{w}{l,k,n}^{\mathrm{H} \, (i)} \mvec{H}{b_y,k,n} \mvec{m}{x,y,n}^{(i)} \right |^2 + N_0 \, \|\mvec{w}{l,k,n}^{(i)}\|^2 \IEEEyessubnumber \label{kkt-mse-4.4} \\
t_{l,k,n}^{(i)} &=&  -\log_2(\epsilon_{l,k,n}^{(i-1)}) - \frac{\left ( \epsilon_{l,k,n}^{(i)} - \epsilon_{l,k,n}^{(i-1)} \right ) }{\log(2) \, \epsilon_{l,k,n}^{(i-1)}} \IEEEyessubnumber \label{kkt-mse-4.5} \\
\sigma_{l,k,n}^{(i)} &=& \left [\tfrac{a_k \, q}{\log(2)}  \, \Big (Q_k - \sum_{n = 1}^N \sum_{l=1}^L t_{l,k,n}^{(i)} \Big )^{(q-1)}\right ]^+  \IEEEyessubnumber \label{kkt-mse-4.2} \\
\alpha^{(i)}_{l,k,n} &=& \alpha^{(i-1)}_{l,k,n} + \rho^{(i)} \left ( \tfrac{\sigma_{l,k,n}^{(i)}}{\epsilon_{l,k,n}^{(i)}} - \alpha^{(i-1)}_{l,k,n} \right ) \IEEEyessubnumber \label{kkt-mse-4.1}
\end{IEEEeqnarray}
}{\allowdisplaybreaks
\begin{IEEEeqnarray}{ll} \label{kkt-mse-4} \neqsub
	\mvec{m}{l,k,n}^{(i)} =& \Big ( \sum_{x \in \mc{U}} \sum_{y=1}^L \alpha_{y,x,n}^{(i-1)} \mvec{H}{b_k,x,n}^\herm \mvec{w}{y,x,n}^{(i-1)} \mvec{w}{y,x,n}^{\herm \, {(i-1)}} \mvec{H}{b_k,x,n} \nonumber \\
	& \qquad {} + \delta_b \mbf{I}_{N_T} \Big )^{-1} \alpha^{(i-1)}_{l,k,n} \mvec{H}{b_k,k,n}^\herm \mvec{w}{l,k,n}^{(i-1)} \IEEEyessubnumber \label{kkt-mse-4.3} \\
	\mvec{w}{l,k,n}^{(i)} =& \Big ( \sum_{x\in\mc{U}}\sum_{y=1}^L \mvec{H}{b_x,k,n} \mvec{m}{y,x,n}^{(i)} \mvec{m}{y,x,n}^{\herm \, (i)} \mvec{H}{b_{x},k,n}^\herm \nonumber \\
	& \qquad {} + \mathbf{I}_{N_R} \Big ) ^{-1} \; \mvec{H}{b_k,k,n} \; \mvec{m}{l,k,n}^{(i)} \IEEEyessubnumber \label{kkt-mse-4.6} \\
	\epsilon_{l,k,n}^{(i)} =& \left | 1 - \mvec{w}{l,k,n}^{\herm \, (i)} \mvec{H}{b_k,k,n} \mvec{m}{l,k,n}^{(i)} \right |^2 + N_0 \, \|\mvec{w}{l,k,n}^{(i)}\|^2 \nonumber \\
	& \qquad{} + \sum_{\mathclap{(x,y) \neq (l,k)}} \left | \mvec{w}{l,k,n}^{\mathrm{H} \, (i)} \mvec{H}{b_y,k,n} \mvec{m}{x,y,n}^{(i)} \right |^2 \IEEEyessubnumber \label{kkt-mse-4.4} \\
	t_{l,k,n}^{(i)} =&  -\log_2(\epsilon_{l,k,n}^{(i-1)}) - \tfrac{\left ( \epsilon_{l,k,n}^{(i)} - \epsilon_{l,k,n}^{(i-1)} \right ) }{\log(2) \, \epsilon_{l,k,n}^{(i-1)}} \IEEEyessubnumber \label{kkt-mse-4.5} \\
	\sigma_{l,k,n}^{(i)} =& \Big [\tfrac{a_k \, q}{\log(2)}  \, \Big (Q_k - \sum_{n = 1}^N \sum_{l=1}^L t_{l,k,n}^{(i)} \Big )^{(q-1)}\Big ]^+  \IEEEyessubnumber \label{kkt-mse-4.2} \\
	\alpha^{(i)}_{l,k,n} =& \alpha^{(i-1)}_{l,k,n} + \rho^{(i)} \left ( \tfrac{\sigma_{l,k,n}^{(i)}}{\epsilon_{l,k,n}^{(i)}} - \alpha^{(i-1)}_{l,k,n} \right ) \IEEEyessubnumber \label{kkt-mse-4.1}
\end{IEEEeqnarray}}
Since the dual variables \me{\alpha^{(i)}} and \me{\sigma^{(i)}} are interdependent in \eqref{kkt-mse-4}, one has to be fixed to optimize for the other. So, \me{\alpha^{(i)}} is fixed to evaluate \me{\sigma^{(i)}} using \eqref{kkt-mse-4}. At iteration \eqn{i}, the dual variables \me{\alpha^{(i)}} is a point in the line segment between \me{\alpha^{(i-1)}} and \me{\tfrac{\sigma^{(i)}}{\epsilon^{(i)}}} determined by using a diminishing or a fixed step size \me{\rho^{(i)} \in (0,1)}. The choice of \eqn{\rho^{(i)}} affects the convergence behavior and also controls the oscillations in the users' rate when \me{\sigma^{(i)}} is negative (before projection) due to over-allocation. In all numerical simulations, the step size \me{\rho^{(i)}} is fixed to \me{0.1} irrespectively. However, the choice of \me{\rho^{(i)}} depends on the system model and it affects the rate of convergence of the iterative algorithm.
	
For a physical interpretation, when the allocated rate \me{t_k^{(i-1)}} is greater than \me{Q_k} for a user \me{k}, the corresponding dual variable \me{\sigma^{(i)}} will be negative and due to the projection operator \me{[x]^+} in \eqref{kkt-mse-4.2}, it will be zero, thereby forcing \me{\alpha_k^{(i)} < \alpha_k^{(i-1)}} as in \eqref{kkt-mse-4.1}. Once \me{\alpha_k^{(i)}} is reduced, the precoder weight in \eqref{kkt-mse-4.3} is lowered to make the rate \me{t_k^{(i)} < t_k^{(i-1)}} eventually. 

The \ac{KKT} expressions in \eqref{kkt-mse-4} are solved in an iterative manner by initializing the transmit and the receive beamformers \me{\mvec{m}{l,k,n},\mvec{w}{l,k,n}} with the single user beamforming and the \ac{MMSE} vectors. The dual variable \me{\alpha}'s are initialized with ones to have equal priorities to all the users in the system. Then the transmit and the receive beamformers are evaluated using the expressions in \eqref{kkt-mse-4}. The transmit precoder in \eqref{kkt-mse-4.3} depends on the \ac{BS} specific dual variable \me{\delta_b}, which can be found by bisection search satisfying the total power constraint \eqref{kkt-mse-1.4}. Note that the fixed \ac{SCA} operating point is given by \me{\tilde{\epsilon}_{l,k,n} = \epsilon_{l,k,n}^{(i-1)}}, which is considered in the expression \eqref{kkt-mse-4}.

To obtain a practical distributed precoder design, we assume that each \ac{BS} \me{b} knows the corresponding equivalent channels \me{\mvec{w}{l,k,n}^\herm \mvec{H}{b,k,n}, \forall k \in {\mc{U}}}, which embeds the receivers \me{\mvec{w}{l,k,n}}, through precoded uplink pilot signaling. We extend the decentralization methods discussed in \cite{komulainen2013effective}, for the current problem as follows. Upon receiving the updated transmit precoders from all \acp{BS} in \me{\mathcal{B}}, each user will evaluate the \ac{MMSE} receiver \eqref{kkt-mse-4.6} and notify to all \acp{BS} by using precoded uplink pilots. On receiving the pilots, each \ac{BS} updates the \ac{MSE} in \eqref{mse-error} as 
\begin{equation}
\epsilon_{l,k,n}^{(i)} = 1 - \mvec{w}{l,k,n}^{(i)\herm} \mvec{H}{b_k,k,n} \mvec{m}{l,k,n}^{(i)}.
\end{equation}
Using \eqn{\epsilon_{l,k,n}^{(i)}}, the variables \me{t_{l,k,n}^{(i)},\sigma_{l,k,n}^{(i)}}, and \me{\alpha_{l,k,n}^{(i)}} are updated using \eqref{kkt-mse-4.5}, \eqref{kkt-mse-4.2} and \eqref{kkt-mse-4.1} respectively, and the obtained dual variables \me{\alpha_{l,k,n}} are exchanged between the \acp{BS} to evaluate the transmit precoders \me{\mvec{m}{l,k,n}^{(i+1)}} for the next iteration. The \ac{SCA} operating point is also updated with the current \ac{MSE} value.
\begin{algorithm}
	\SetAlgoLined
	\DontPrintSemicolon
	\BlankLine
	\SetKwInput{KwInit}{Initialize}
	\KwIn{\me{a_k, \, Q_k, \, \mvec{H}{b,k,n},\; \fall b \in \mathcal{B}, \, \fall k \in \mathcal{U}, \fall n \in \mathcal{N}}}
	\KwOut{\me{\mvec{m}{l,k,n}} and \me{\mvec{w}{l,k,n} \fall l \in \set{1,2,\dotsc,L}}}
	\KwInit{\me{i=1}, \me{\mbf{w}^{(0)}_{l,k,n}, \tilde{\epsilon}_{l,k,n}} randomly, dual variables \me{{\alpha}_{l,k,n}^{(0)} = 1}, and \me{I_{\max}} for certain value}
	\ForEach{\ac{BS} \me{b \in \mc{B}}}{
		\Repeat{until convergence or \me{i \geq I_{\max}}}{
			update \me{\mvec{m}{l,k,n}^{(i)}} using \eqref{kkt-mse-4.3}, and perform precoded downlink pilot transmission \;
			find \me{\mvec{w}{l,k,n}^{(i)}} using \eqref{kkt-mse-4.6} at each user \;
			evaluate \me{\epsilon_{l,k,n}^{(i)}}, \me{t_{l,k,n}^{(i)}}, \me{\sigma_{l,k,n}^{(i)}} and \me{\alpha_{l,k,n}^{(i)}} using \eqref{kkt-mse-4.4} and \eqref{kkt-mse-4.5}, \eqref{kkt-mse-4.2} and \eqref{kkt-mse-4.1} at each user with the updated \me{\mvec{w}{l,k,n}^{(i)}} \;
			using precoded uplink pilots, \me{\mvec{m}{l,k,n}^{(i)}} and \me{\alpha_{l,k,n}^{(i)}} are notified to all \acp{BS} in \me{\mathcal{B}} \;
			\me{i = i + 1} \;
		}
	}
	\caption{\ac{KKT} approach for the \ac{JSFRA} scheme}
	\label{algo-4}
\end{algorithm}

To avoid the back-haul exchanges between the \acp{BS}, as an alternative approach, users can perform all the required processing and \acp{BS} will update the precoders based on the feedback from all the users. Upon receiving the transmit precoders from the \acp{BS}, each user will update the receive beamformer \me{\mvec{w}{l,k,n}}, the \ac{MSE} \me{\epsilon_{l,k,n}}, and the dual variables \me{\sigma_{l,k,n}} and \me{\alpha_{l,k,n}}. Then, the updated \me{\alpha_{l,k,n}} and \me{\mvec{w}{l,k,n}} are notified to the \acp{BS} using two separate precoded uplink pilots with \me{\tilde{\mbf{w}}_{l,k,n}^{(i)} = \sqrt{\alpha_{l,k,n}^{(i)}}\mvec{w}{l,k,n}^{\ast(i)}} and \me{\bar{\mbf{w}}_{l,k,n}^{(i)} = \alpha_{l,k,n}^{(i)}\mvec{w}{l,k,n}^{\ast(i)}} as the precoders, where \me{\mbf{x}^{\ast}} is the complex conjugate of \me{\mbf{x}}. Upon receiving the precoded uplink pilots, each \ac{BS} evaluates the equivalent channels \me{\mvec{H}{b,k,n}^{\mathrm{T}} \tilde{\mbf{w}}_{l,k,n}^{(i)}} and \me{\mvec{H}{b,k,n}^{\mathrm{T}} \bar{\mbf{w}}_{l,k,n}^{(i)}} to update the transmit precoders using \eqref{kkt-mse-4.3}. Algorithm \ref{algo-4} outlines a practical way of updating the transmit and the receive beamformers by using \ac{OTA} signaling as in \cite{komulainen2013effective}.


\review{To conclude this section, we provide some remarks regarding the choices of centralized and distributed algorithms under some scenarios. We can choose the \ac{JSFRA} formulation via either \ac{SINR} relaxation (Sect. \ref{sec-3.2.1}) or \ac{MSE} equivalence (Sect. \ref{sec-3.3}) equally when \eqn{N_R > 1}. However, for \eqn{N_R = 1} scenario, the \ac{JSFRA} formulation in Section \ref{sec-3.2.1} is more efficient, as there is no receiver update, and therefore has less complexity. Similarly, when \eqn{N_R = 1}, the distributed approaches based on the \ac{JSFRA} method via \ac{SINR} relaxation are preferred over other schemes due to the limited signaling between the coordinating \acp{BS} involving the exchange of the scalar interference values. However, when \eqn{N_R > 1}, the \ac{KKT} scheme presented in Section \ref{sec-4.3} has less signaling requirements for a given throughput improvement.}

%\subsubsection*{Convergence}
%The iterative method presented in Algorithm \ref{algo-4} converges to a stationary point at each iteration. Since the \ac{SCA} point \me{\tilde{\epsilon}_{l,k,n}} and the receive beamformers are updated together at each iteration, the convergence proof can be argued based on the monotonic increase in the objective function at each iteration. In order to illustrate the convergence, we adopt the following argument. The transmit precoders in \eqref{kkt-mse-4.3} improves the objective function after each update following the \ac{SCA} operating point \me{\tilde{\epsilon}_{l,k,n}} update \cite{marks1978technical}. Furthermore, the \ac{MMSE} receivers are globally optimal for the fixed transmit precoders \cite{christensen2008weighted,wmmse_shi}, the alternating beamformer updates improve the objective function monotonically in spite of having a subgradient like update in \eqref{kkt-mse-4.1}.
%presented in Algorithm \ref{algo-4} converges to a stationary point if the dual variables \me{\alpha_{l,k,n}} are allowed to converge or for fixed number of iterations \me{J_{\max}}. The convergence of the dual variable is guaranteed, since the problem is convex by fixing the receive beamformers \me{\mvec{w}{l,k,n}} and the operating \ac{MSE} point \me{\epsilon_{l,k,n}} \cite{boyd2011distributed}. Once the dual variables are converged or iterated for certain accuracy, the receivers are updated using the \ac{MMSE} objective. Since the \ac{MMSE} receiver is optimal for the fixed transmit precoders, the objective function will improve or stays the same after the receiver update leading to a monotonic convergence of the iterative algorithm provided in \eqref{kkt-mse-4}.
