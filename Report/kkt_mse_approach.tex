
The distributed solutions via primal and \ac{ADMM} approaches depend on the subgradient update by using a step size parameter for the coupling variables. It affects the speed of convergence to the optimal value. In this method, we provide an alternative approach to decentralize the \ac{MSE} equivalent problem considered in \cite{christensen2008weighted,wmmse_shi} by directly solving the \ac{KKT} conditions. Similar work has been considered for the \ac{WSRM} problem with the minimum rate constraints in \cite{kaleva2013decentralized,kaleva2013primal}. When the queues are involved, the maximum rate constraint imposed by the number of queued packets at the \ac{BS} includes a nonconvex constraint, which makes the problem difficult to solve due to the additional nonconvex maximum rate constraint \eqref{eqn-3.1.4} for the \ac{WSRM} problem.

Even though the rate constraints are implicitly present in the objective function, we cannot formulate the \ac{KKT} conditions readily due to the non-differentiable objective function. The non-differentiability is due to the absolute operator present in the norm function. In order to make the objective function differentiable, we consider the following case for which the absolute operator can be ignored without affecting the optimal solution, namely,
\begin{itemize}
\item when the exponent \me{q} is even, or
\item when the number of backlogged packets of each user is large enough, \textit{i.e}, \me{Q_k \gg \sum_{n=1}^N \sum_{l=1}^L {t}_{l,k,n}} to ignore the absolute operator, which means also ignoring the queues in the first place as well.
\end{itemize}

With the assumption of either one of the above conditions to be true, the problem in \eqref{eqn-mse-2} can be written as
\iftoggle{single_column}{\allowdisplaybreaks
\begin{IEEEeqnarray}{rCl}\label{kkt-mse-1}
\underset{\substack{t_{l,k,n},\mvec{M}{k,n}, \\ \epsilon_{l,k,n}, \mvec{W}{k,n}}}{\text{minimize}} &\hspace{0.5cm}& \sum_{b \in \mc{B}} \sum_{k \in \mc{U}_b} \, a_k \, \Big ( Q_k - \sum_{n = 1}^N \sum_{l = 1}^{L} t_{l,k,n} \Big )^q \IEEEyessubnumber \label{kkt-mse-1.1} \\
\text{subject to} & \hspace{0.5cm} & \nonumber \\
\alpha_{l,k,n} : & \hspace{0.5cm} & \left | 1 - \mvec{w}{l,k,n}^\herm \mvec{H}{b_k,k,n} \mvec{m}{l,k,n} \right |^2 +  N_0 \, \|\mvec{w}{l,k,n}\|^2 + \sum_{\mathclap{(x,y) \neq (l,k)}} \left | \mvec{w}{l,k,n}^\herm \mvec{H}{b_y,k,n} \mvec{m}{x,y,n} \right |^2 \leq \epsilon_{l,k,n} \eqspace \IEEEyessubnumber \label{kkt-mse-1.2} \\
\sigma_{l,k,n} : & \hspace{0.5cm} & \log(\tilde{\epsilon}_{l,k,n}) + \frac{\left ( {\epsilon}_{l,k,n} - \tilde{\epsilon}_{l,k,n} \right ) }{\tilde{\epsilon}_{l,k,n}} \leq -t_{l,k,n} \, \log(2) \IEEEyessubnumber \label{kkt-mse-1.3} \\
\delta_b : & \hspace{0.5cm} & \sum_{n = 1}^N \sum_{k \in \mathcal{U}_b} \sum_{l = 1}^L \text{tr} \, (\mvec{m}{l,k,n} \mvec{m}{l,k,n}^\herm) \leq P_{{\max}}, \fall b, \IEEEyessubnumber \label{kkt-mse-1.4}
\end{IEEEeqnarray}
}{
\begin{IEEEeqnarray}{Rl}\label{kkt-mse-1}
	\underset{\substack{t_{l,k,n},\mvec{M}{k,n}, \\ \epsilon_{l,k,n}, \mvec{W}{k,n}}}{\text{minimize}} & \quad \sum_{b \in \mc{B}} \sum_{k \in \mc{U}_b} \, a_k \, \Big ( Q_k - \sum_{n = 1}^N \sum_{l = 1}^{L} t_{l,k,n} \Big )^q \IEEEyessubnumber \label{kkt-mse-1.1} \\
	\text{subject to} & \nonumber \\
	\alpha_{l,k,n} : &  \left | 1 - \mvec{w}{l,k,n}^\herm \mvec{H}{b_k,k,n} \mvec{m}{l,k,n} \right |^2 +  N_0 \|\mvec{w}{l,k,n}\|^2 \nonumber \\
	& + \sum_{\mathclap{(x,y) \neq (l,k)}} \left | \mvec{w}{l,k,n}^\herm \mvec{H}{b_y,k,n} \mvec{m}{x,y,n} \right |^2 \leq \epsilon_{l,k,n} \IEEEyessubnumber \label{kkt-mse-1.2} \\
	\sigma_{l,k,n} : &  \log_2(\tilde{\epsilon}_{l,k,n}) + \frac{\left ( {\epsilon}_{l,k,n} - \tilde{\epsilon}_{l,k,n} \right ) }{\log(2)\tilde{\epsilon}_{l,k,n}} \leq -t_{l,k,n} \IEEEyessubnumber \label{kkt-mse-1.3} \\
	\delta_b : & \sum_{n = 1}^N \sum_{k \in \mathcal{U}_b} \sum_{l = 1}^L \text{tr} \, (\mvec{m}{l,k,n} \mvec{m}{l,k,n}^\herm) \leq P_{{\max}}, \fall b, \IEEEyessubnumber \eqspace \label{kkt-mse-1.4}
\end{IEEEeqnarray}
}
where \me{\alpha_{l,k,n},\sigma_{l,k,n}} and \me{\delta_b} are the dual variables corresponding to the constraints defined in \eqref{kkt-mse-1.2}, \eqref{kkt-mse-1.3} and \eqref{kkt-mse-1.4}. 

The problem in \eqref{kkt-mse-1} is solved using the \ac{KKT} expressions, which is obtained by taking the derivative of the Lagrangian function w.r.t the primal and the dual variables as shown in the Appendix \ref{a-1}. Upon solving, we obtain the iterative solution as
\iftoggle{single_column}{
\begin{IEEEeqnarray}{rCl} \label{kkt-mse-4}
\mvec{m}{l,k,n}^{(i)} &=& \Big ( \sum_{x \in \mc{U}} \sum_{y=1}^L \alpha_{y,x,n}^{(i-1)} \mvec{H}{b_k,x,n}^\herm \mvec{w}{y,x,n}^{(i-1)} \mvec{w}{y,x,n}^{\herm \, {(i-1)}} \mvec{H}{b_k,x,n} + \delta_b \mbf{I}_{N_T} \Big )^{-1} \alpha^{(i-1)}_{l,k,n} \mvec{H}{b_k,k,n}^\herm \mvec{w}{l,k,n}^{(i-1)} \IEEEyessubnumber \label{kkt-mse-4.3} \\
\epsilon_{l,k,n}^{(i)} &=& \left | 1 - \mvec{w}{l,k,n}^{\herm \, (i-1)} \mvec{H}{b_k,k,n} \mvec{m}{l,k,n}^{(i)} \right |^2 + \sum_{\mathclap{(x,y) \neq (l,k)}} \left | \mvec{w}{l,k,n}^{\mathrm{H} \, (i-1)} \mvec{H}{b_y,k,n} \mvec{m}{x,y,n}^{(i)} \right |^2 + N_0 \, \|\mvec{w}{l,k,n}^{(i-1)}\|^2 \IEEEyessubnumber \label{kkt-mse-4.4} \\
t_{l,k,n}^{(i)} &=&  -\log_2(\epsilon_{l,k,n}^{(i-1)}) - \frac{\left ( \epsilon_{l,k,n}^{(i)} - \epsilon_{l,k,n}^{(i-1)} \right ) }{\log(2) \, \epsilon_{l,k,n}^{(i-1)}} \IEEEyessubnumber \label{kkt-mse-4.5} \\
\sigma_{l,k,n}^{(i)} &=& \left [\tfrac{a_k \, q}{\log(2)}  \, \Big (Q_k - \sum_{n = 1}^N \sum_{l=1}^L t_{l,k,n}^{(i)} \Big )^{(q-1)}\right ]^+  \IEEEyessubnumber \label{kkt-mse-4.2} \\
\alpha^{(i)}_{l,k,n} &=& \alpha^{(i-1)}_{l,k,n} + \rho \left ( \tfrac{\sigma_{l,k,n}^{(i)}}{\epsilon_{l,k,n}^{(i)}} - \alpha^{(i-1)}_{l,k,n} \right ) \IEEEyessubnumber \label{kkt-mse-4.1} \\
\mvec{w}{l,k,n}^{(i)} &=& \Big ( \sum_{x\in\mc{U}}\sum_{y=1}^L \mvec{H}{b_x,k,n} \mvec{m}{y,x,n}^{(i)} \mvec{m}{y,x,n}^{\herm \, (i)} \mvec{H}{b_{x},k,n}^\herm + \mathbf{I}_{N_R} \Big ) ^{-1} \; \mvec{H}{b_k,k,n} \; \mvec{m}{l,k,n}^{(i)}. \IEEEyessubnumber \label{kkt-mse-4.6}
\end{IEEEeqnarray}
}{{\allowdisplaybreaks
\begin{IEEEeqnarray}{ll} \label{kkt-mse-4}
	\mvec{m}{l,k,n}^{(i)} =& \Big ( \sum_{x \in \mc{U}} \sum_{y=1}^L \alpha_{y,x,n}^{(i-1)} \mvec{H}{b_k,x,n}^\herm \mvec{w}{y,x,n}^{(i-1)} \mvec{w}{y,x,n}^{\herm \, {(i-1)}} \mvec{H}{b_k,x,n} \nonumber \\
	& \qquad {} + \delta_b \mbf{I}_{N_T} \Big )^{-1} \alpha^{(i-1)}_{l,k,n} \mvec{H}{b_k,k,n}^\herm \mvec{w}{l,k,n}^{(i-1)} \IEEEyessubnumber \label{kkt-mse-4.3} \\
	\epsilon_{l,k,n}^{(i)} =& \left | 1 - \mvec{w}{l,k,n}^{\herm \, (i-1)} \mvec{H}{b_k,k,n} \mvec{m}{l,k,n}^{(i)} \right |^2 + N_0 \, \|\mvec{w}{l,k,n}^{(i-1)}\|^2 \nonumber \\
	& \qquad{} + \sum_{\mathclap{(x,y) \neq (l,k)}} \left | \mvec{w}{l,k,n}^{\mathrm{H} \, (i-1)} \mvec{H}{b_y,k,n} \mvec{m}{x,y,n}^{(i)} \right |^2 \IEEEyessubnumber \label{kkt-mse-4.4} \\
	t_{l,k,n}^{(i)} =&  -\log_2(\epsilon_{l,k,n}^{(i-1)}) - \tfrac{\left ( \epsilon_{l,k,n}^{(i)} - \epsilon_{l,k,n}^{(i-1)} \right ) }{\log(2) \, \epsilon_{l,k,n}^{(i-1)}} \IEEEyessubnumber \label{kkt-mse-4.5} \\
	\sigma_{l,k,n}^{(i)} =& \Big [\tfrac{a_k \, q}{\log(2)}  \, \Big (Q_k - \sum_{n = 1}^N \sum_{l=1}^L t_{l,k,n}^{(i)} \Big )^{(q-1)}\Big ]^+  \IEEEyessubnumber \label{kkt-mse-4.2} \\
	\alpha^{(i)}_{l,k,n} =& \alpha^{(i-1)}_{l,k,n} + \rho \left ( \tfrac{\sigma_{l,k,n}^{(i)}}{\epsilon_{l,k,n}^{(i)}} - \alpha^{(i-1)}_{l,k,n} \right ) \IEEEyessubnumber \label{kkt-mse-4.1} \\
	\mvec{w}{l,k,n}^{(i)} =& \Big ( \sum_{x\in\mc{U}}\sum_{y=1}^L \mvec{H}{b_x,k,n} \mvec{m}{y,x,n}^{(i)} \mvec{m}{y,x,n}^{\herm \, (i)} \mvec{H}{b_{x},k,n}^\herm \nonumber \\
	& \qquad {} + \mathbf{I}_{N_R} \Big ) ^{-1} \; \mvec{H}{b_k,k,n} \; \mvec{m}{l,k,n}^{(i)}. \IEEEyessubnumber \label{kkt-mse-4.6}
\end{IEEEeqnarray}}}
Since the dual variables \me{\alpha^{(i)}} and \me{\sigma^{(i)}} are interdependent in \eqref{kkt-mse-4}, one has to be fixed to optimize for the other. In this problem, we fix the dual variable \me{\alpha^{(i)}} to a fixed value as in \eqref{kkt-mse-4.1} to obtain the other variables in \eqref{kkt-mse-4}. At each iteration, the dual variable \me{\alpha^{(i)}} is updated linearly from the earlier value \me{\alpha^{(i-1)}} by a step size of \me{\rho \in [0,1]}. It can be seen that, when the allocated rate \me{t_k^{(i-1)}} is greater than the number of queued packets \me{Q_k} for a user \me{k}, the corresponding dual variable \me{\sigma^{(i)}} will be negative thereby forcing the dual variable \me{\alpha_k^{(i)} < \alpha_k^{(i-1)}}, which in turn reduces the transmit precoder weights in \eqref{kkt-mse-4.3}. This reduction in the precoder weights forces the allocated rate of user \me{k} to reduce from the previous iteration as \me{t_k^{(i)} < t_k^{(i-1)}}. 

The \ac{KKT} solutions provided in \eqref{kkt-mse-4} are solved in an iterative manner by initializing the transmit and the receive precoders \me{\mvec{M}{k,n},\mvec{W}{k,n}} with the single user beamforming and the \ac{MMSE} vectors. The dual variable \me{\alpha}'s corresponding to precoder weights are initialized with ones to provide equal priorities to all streams. Now, the closed form expressions in \eqref{kkt-mse-4} are evaluated sequentially until convergence or to a certain accuracy. In \eqref{kkt-mse-4}, all expressions are in a closed form except the transmit precoders \eqref{kkt-mse-4.3}, which depend on the \ac{BS} specific dual variable \me{\delta_b}. It can be solved efficiently by the bisection method satisfying the power constraint \eqref{kkt-mse-1.4}. After each iteration instant, the transmit and the receive precoders are updated across the coordinating \acp{BS} in \me{\mc{B}} to obtain the next operating point.

In order to find the distributed solution, we can consider the method proposed in \cite{komulainen2013effective}, where the users evaluate the \ac{MSE} and the dual variable \me{\alpha_{l,k,n}} using the transmission made by all \acp{BS} and the updated transmit precoders \me{\mvec{m}{l,k,n}^{(i-1)}}. Once the dual variables are evaluated, the users will notify the dual variables and the receive beamformers to the \acp{BS} using the uplink precoded pilots, where the uplink precoder is \me{\mvec{\tilde{w}}{l,k,n}^{(i-1)} = \sqrt{\alpha_{l,k,n}^{(i-1)}}\mvec{w}{l,k,n}^{\ast(i-1)}}. Upon receiving the uplink precoded pilots at the \ac{BS} \me{b}, the effective channel \me{\mvec{H}{b,k,n}^{\mathrm{T}} \mvec{\tilde{w}}{l,k,n}^{(i-1)}} can be measured and used in the expression \eqref{kkt-mse-4.3} to update the transmit precoders, where \me{\mbf{x}^{\ast}} represents the conjugate of \me{\mbf{x}}. The algorithmic representation of the distributed \ac{MSE}-\ac{KKT} scheme is shown in the Algorithm. \ref{algo-4}.
\begin{algorithm}
 \SetAlgoLined
 \DontPrintSemicolon
 \BlankLine
 \SetKwInput{KwInit}{Initialize}
 \KwIn{\me{a_k, \, Q_k, \, \mvec{H}{b,k,n},\; \fall b \in \mathcal{B}, \, \fall k \in \mathcal{U}, \fall n \in \mathcal{N}}}
 \KwOut{\me{\mvec{m}{l,k,n}} and \me{\mvec{w}{l,k,n} \fall l \in \set{1,2,\dotsc,L}}}
 \KwInit{\me{i=1}, \me{\mbf{w}^{(0)}_{l,k,n},\epsilon_{l,k,n}^{(0)}} randomly, dual variables \me{{\alpha}_{l,k,n}^{(0)} = 1}, and \me{I_{\max}}}
 \ForEach{\ac{BS} \me{b \in \mc{B}}}{
 initialize \me{i = 0} \;
 \Repeat{until convergence or \me{i \geq I_{\max}}}{
	find \me{\mvec{M}{k,n}^{(i)}} using \eqref{kkt-mse-4.3}, where \me{\delta_b} is obtained by bisection search satisfying \eqref{kkt-mse-1.4} \;
	update \me{\epsilon_{l,k,n}^{(i)}}, \me{t_{l,k,n}^{(i)}}, \me{\sigma_{l,k,n}^{(i)}} and \me{\alpha_{l,k,n}^{(i)}} using \eqref{kkt-mse-4.4} and \eqref{kkt-mse-4.5}, \eqref{kkt-mse-4.2} and \eqref{kkt-mse-4.1} at \ac{BS} \me{b} and perform precoded downlink pilot transmission with \me{\mvec{M}{k,n}^{(i)}}\;
	update \me{\mvec{W}{k,n}^{(i+1)}} using \eqref{kkt-mse-4.6} and notify to all \acp{BS} using uplink precoded pilot with \me{\mvec{\tilde{w}}{l,k,n}^{(i+1)}} as the precoder\;
	\me{i = i + 1} \;
 }
 }
 \caption{\ac{KKT} approach for the \ac{JSFRA} scheme}
 \label{algo-4}
\end{algorithm}

\subsubsection*{Convergence}
The iterative method presented in Algorithm \ref{algo-4} converges to a stationary point if the dual variables \me{\alpha_{l,k,n}} are allowed to converge or for fixed number of iterations \me{J_{\max}}. The convergence of the dual variable is guaranteed, since the problem is convex by fixing the receive beamformers \me{\mvec{w}{l,k,n}} and the operating \ac{MSE} point \me{\epsilon_{l,k,n}} \cite{boyd2011distributed}. Once the dual variables are converged or iterated for certain accuracy, the receivers are updated using the \ac{MMSE} objective. Since the \ac{MMSE} receiver is optimal for the fixed transmit precoders, the objective function will improve or stays the same after the receiver update leading to a monotonic convergence of the iterative algorithm provided in \eqref{kkt-mse-4}.
